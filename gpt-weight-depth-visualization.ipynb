{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:05:38.432974Z",
     "iopub.status.busy": "2026-02-28T16:05:38.432683Z",
     "iopub.status.idle": "2026-02-28T16:06:05.235163Z",
     "shell.execute_reply": "2026-02-28T16:06:05.234377Z",
     "shell.execute_reply.started": "2026-02-28T16:05:38.432927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flax.training import checkpoints\n",
    "from flax.traverse_util import flatten_dict\n",
    "from scipy.stats import kurtosis\n",
    "import optax\n",
    "\n",
    "from train import TrainConfig, init_train_state, get_default_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:06:13.665075Z",
     "iopub.status.busy": "2026-02-28T16:06:13.664535Z",
     "iopub.status.idle": "2026-02-28T16:06:13.673278Z",
     "shell.execute_reply": "2026-02-28T16:06:13.672484Z",
     "shell.execute_reply.started": "2026-02-28T16:06:13.665052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainConfig(seed=555, out_dir='out', train_pattern='openwebtext/train_??.tfrecord', val_pattern='openwebtext/val_??.tfrecord', shuffle_buffer_size=128, eval_interval=1000, eval_steps=50, eval_only=False, keep_checkpoints=6, batch_size=16, train_steps=150000, weight_decay=0.1, grad_clip=1.0, gradient_accumulation_steps=1, betas=[0.9, 0.95], learning_rate=CosineDecayScheduleConfig(init_value=0.0, peak_value=0.00064, warmup_steps=1000, decay_steps=150000, end_value=6.4e-05), wandb=WandbConfig(entity='jenkspt', project='owt', name='gpt-124m', mode='online', notes=''), model=GPTConfig(block_size=1024, vocab_size=50304, num_layers=12, num_heads=12, num_embeds=768, dropout_rate=0.0, use_bias=True, dtype='bfloat16'), remat=False)\n"
     ]
    }
   ],
   "source": [
    "config = get_default_config()\n",
    "num_heads = config.model.num_heads\n",
    "hidden_size = config.model.num_embeds\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:06:13.674456Z",
     "iopub.status.busy": "2026-02-28T16:06:13.674183Z",
     "iopub.status.idle": "2026-02-28T16:06:13.685027Z",
     "shell.execute_reply": "2026-02-28T16:06:13.684429Z",
     "shell.execute_reply.started": "2026-02-28T16:06:13.674434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(config, ckpt_dir):\n",
    "    key = jax.random.PRNGKey(config.seed)\n",
    "    learning_rate = optax.warmup_cosine_decay_schedule(**vars(config.learning_rate))\n",
    "    train_state = init_train_state(key, config, learning_rate)\n",
    "    train_state = checkpoints.restore_checkpoint(ckpt_dir, train_state)\n",
    "    print(\"Loaded step:\", int(train_state.step))\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:06:13.686061Z",
     "iopub.status.busy": "2026-02-28T16:06:13.685864Z",
     "iopub.status.idle": "2026-02-28T16:06:14.602706Z",
     "shell.execute_reply": "2026-02-28T16:06:14.602013Z",
     "shell.execute_reply.started": "2026-02-28T16:06:13.686042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from scipy.stats import kurtosis, skew\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:06:14.603884Z",
     "iopub.status.busy": "2026-02-28T16:06:14.603532Z",
     "iopub.status.idle": "2026-02-28T16:06:14.608870Z",
     "shell.execute_reply": "2026-02-28T16:06:14.608125Z",
     "shell.execute_reply.started": "2026-02-28T16:06:14.603840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DistributionMetric:\n",
    "    def __init__(self, name, compute_fn, requires_matrix=False):\n",
    "        self.name = name\n",
    "        self.compute_fn = compute_fn\n",
    "        self.requires_matrix = requires_matrix\n",
    "\n",
    "\n",
    "METRIC_REGISTRY = {}\n",
    "\n",
    "def register_metric(metric: DistributionMetric):\n",
    "    METRIC_REGISTRY[metric.name] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:06:14.609902Z",
     "iopub.status.busy": "2026-02-28T16:06:14.609687Z",
     "iopub.status.idle": "2026-02-28T16:06:14.622705Z",
     "shell.execute_reply": "2026-02-28T16:06:14.622076Z",
     "shell.execute_reply.started": "2026-02-28T16:06:14.609882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---- Basic distribution metrics ----\n",
    "\n",
    "def metric_mean(w):\n",
    "    return float(np.mean(w))\n",
    "\n",
    "def metric_std(w):\n",
    "    return float(np.std(w))\n",
    "\n",
    "def metric_skew(w):\n",
    "    return float(skew(w))\n",
    "\n",
    "def metric_kurtosis(w):\n",
    "    return float(kurtosis(w, fisher=True))\n",
    "\n",
    "\n",
    "# ---- Norm based ----\n",
    "\n",
    "def metric_l2_norm(w):\n",
    "    return float(np.linalg.norm(w))\n",
    "\n",
    "\n",
    "# ---- Matrix based ----\n",
    "\n",
    "def metric_spectral_norm(w):\n",
    "    u, s, v = np.linalg.svd(w, full_matrices=False)\n",
    "    return float(np.max(s))\n",
    "\n",
    "\n",
    "def metric_effective_rank(w):\n",
    "    u, s, v = np.linalg.svd(w, full_matrices=False)\n",
    "    s = s / np.sum(s)\n",
    "    entropy = -np.sum(s * np.log(s + 1e-8))\n",
    "    return float(np.exp(entropy))\n",
    "\n",
    "\n",
    "# Register defaults\n",
    "register_metric(DistributionMetric(\"mean\", metric_mean))\n",
    "register_metric(DistributionMetric(\"std\", metric_std))\n",
    "register_metric(DistributionMetric(\"skew\", metric_skew))\n",
    "register_metric(DistributionMetric(\"kurtosis\", metric_kurtosis))\n",
    "register_metric(DistributionMetric(\"l2_norm\", metric_l2_norm))\n",
    "register_metric(DistributionMetric(\"spectral_norm\", metric_spectral_norm, requires_matrix=True))\n",
    "register_metric(DistributionMetric(\"effective_rank\", metric_effective_rank, requires_matrix=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T16:06:14.639176Z",
     "iopub.status.busy": "2026-02-28T16:06:14.638601Z",
     "iopub.status.idle": "2026-02-28T16:06:14.651348Z",
     "shell.execute_reply": "2026-02-28T16:06:14.650809Z",
     "shell.execute_reply.started": "2026-02-28T16:06:14.639155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class WeightStatisticsEngine:\n",
    "    def __init__(self, params, num_heads, hidden_size,\n",
    "                 sample_size=100_000):\n",
    "        self.params = params\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Flatten Flax param tree\n",
    "    # ---------------------------------\n",
    "    def _flatten_flax_dict(self, d, parent_key=\"\"):\n",
    "        items = {}\n",
    "        for k, v in d.items():\n",
    "            new_key = f\"{parent_key}.{k}\" if parent_key else k\n",
    "            if isinstance(v, dict):\n",
    "                items.update(self._flatten_flax_dict(v, new_key))\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "        return items\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Extract layer index\n",
    "    # ---------------------------------\n",
    "    def _extract_layer_id(self, key):\n",
    "        for part in key.split(\".\"):\n",
    "            if part.isdigit():\n",
    "                return int(part)\n",
    "        return None\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Metric computation\n",
    "    # ---------------------------------\n",
    "    def _compute_metrics(self, tensor, selected_metrics):\n",
    "        results = {}\n",
    "\n",
    "        flat = tensor.flatten()\n",
    "\n",
    "        if self.sample_size and flat.size > self.sample_size:\n",
    "            idx = np.random.choice(flat.size, self.sample_size, replace=False)\n",
    "            flat = flat[idx]\n",
    "\n",
    "        for metric_name in selected_metrics:\n",
    "            metric = METRIC_REGISTRY[metric_name]\n",
    "\n",
    "            if metric.requires_matrix:\n",
    "                value = metric.compute_fn(tensor)\n",
    "            else:\n",
    "                value = metric.compute_fn(flat)\n",
    "\n",
    "            results[metric_name] = float(value)\n",
    "\n",
    "        return results\n",
    "\n",
    "    # ---------------------------------\n",
    "    # MAIN COMPUTE\n",
    "    # ---------------------------------\n",
    "    def compute(self, selected_metrics):\n",
    "\n",
    "        flat_params = self._flatten_flax_dict(self.params)\n",
    "\n",
    "        results = {\n",
    "            \"layer_stats\": defaultdict(dict),\n",
    "            \"head_stats\": defaultdict(lambda: defaultdict(dict))\n",
    "        }\n",
    "\n",
    "        for key, tensor in flat_params.items():\n",
    "\n",
    "            if \"kernel\" not in key:\n",
    "                continue\n",
    "\n",
    "            layer_id = self._extract_layer_id(key)\n",
    "            if layer_id is None:\n",
    "                continue\n",
    "\n",
    "            w = np.array(tensor)\n",
    "\n",
    "            # ---------------------------------\n",
    "            # 1️⃣ Layer-wise distribution\n",
    "            # ---------------------------------\n",
    "            layer_metrics = self._compute_metrics(w, selected_metrics)\n",
    "            results[\"layer_stats\"][layer_id][key] = layer_metrics\n",
    "\n",
    "            # ---------------------------------\n",
    "            # 2️⃣ Head-wise distribution\n",
    "            # Only for attention projections\n",
    "            # ---------------------------------\n",
    "            if \"c_attn\" not in key:\n",
    "                continue\n",
    "\n",
    "            if w.ndim != 2 or w.shape[1] != 3 * self.hidden_size:\n",
    "                continue\n",
    "\n",
    "            q, k, v = np.split(w, 3, axis=1)\n",
    "\n",
    "            for proj_name, proj_matrix in zip([\"Q\", \"K\", \"V\"], [q, k, v]):\n",
    "\n",
    "                proj_matrix = proj_matrix.reshape(\n",
    "                    self.hidden_size,\n",
    "                    self.num_heads,\n",
    "                    self.head_dim\n",
    "                )\n",
    "\n",
    "                for head in range(self.num_heads):\n",
    "                    head_tensor = proj_matrix[:, head, :]\n",
    "\n",
    "                    head_metrics = self._compute_metrics(\n",
    "                        head_tensor,\n",
    "                        selected_metrics\n",
    "                    )\n",
    "\n",
    "                    results[\"head_stats\"][layer_id][proj_name][\n",
    "                        f\"head_{head}\"\n",
    "                    ] = head_metrics\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "\n",
    "class LLMDistributionVisualizer:\n",
    "    def __init__(self, weight_stats=None,\n",
    "                 log_scale=False, use_wandb=False, project=None):\n",
    "\n",
    "        self.weight_stats = weight_stats\n",
    "        self.log_scale = log_scale\n",
    "        self.use_wandb = use_wandb\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.init(project=project or \"llm-distribution\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1️⃣ LAYER-WISE METRICS\n",
    "    # --------------------------------------------------\n",
    "    def plot_weight_metric_layerwise(self, metric_name):\n",
    "\n",
    "        layer_stats = self.weight_stats[\"layer_stats\"]\n",
    "\n",
    "        layers = sorted(layer_stats.keys())\n",
    "        values = []\n",
    "\n",
    "        for l in layers:\n",
    "            vals = [\n",
    "                layer_stats[l][k][metric_name]\n",
    "                for k in layer_stats[l]\n",
    "                if metric_name in layer_stats[l][k]\n",
    "            ]\n",
    "            values.append(np.mean(vals))\n",
    "\n",
    "        table = wandb.Table(columns=[\"Layer\", metric_name])\n",
    "\n",
    "        for layer, value in zip(layers, values):\n",
    "            table.add_data(layer, value)\n",
    "\n",
    "        wandb.log({\n",
    "            f\"Layer vs {metric_name}\":\n",
    "                wandb.plot.line(\n",
    "                    table,\n",
    "                    x=\"Layer\",\n",
    "                    y=metric_name,\n",
    "                    title=f\"Layer vs {metric_name}\"\n",
    "                )\n",
    "        })\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2️⃣ HEAD-WISE METRICS\n",
    "    # --------------------------------------------------\n",
    "    def plot_weight_metric_headwise(self, metric_name, layer_id):\n",
    "\n",
    "        head_stats = self.weight_stats[\"head_stats\"]\n",
    "\n",
    "        if layer_id not in head_stats:\n",
    "            return\n",
    "\n",
    "        table = wandb.Table(columns=[\"Head\", metric_name, \"Projection\"])\n",
    "\n",
    "        for proj in head_stats[layer_id]:  # Q, K, V\n",
    "            for head in head_stats[layer_id][proj]:\n",
    "                if metric_name in head_stats[layer_id][proj][head]:\n",
    "                    value = head_stats[layer_id][proj][head][metric_name]\n",
    "                    table.add_data(head, value, proj)\n",
    "\n",
    "        wandb.log({\n",
    "            f\"Layer {layer_id} Head Distribution ({metric_name})\":\n",
    "                wandb.plot.bar(\n",
    "                    table,\n",
    "                    \"Head\",\n",
    "                    metric_name,\n",
    "                    title=f\"Layer {layer_id} Head Distribution ({metric_name})\"\n",
    "                )\n",
    "        })\n",
    "\n",
    "    def plot_projection_metric_headwise_line(self, metric_name, layer_id, projection=\"Q\"):\n",
    "    \n",
    "        head_stats = self.weight_stats[\"head_stats\"]\n",
    "\n",
    "        if layer_id not in head_stats:\n",
    "            return\n",
    "\n",
    "        if projection not in head_stats[layer_id]:\n",
    "            return\n",
    "\n",
    "        table = wandb.Table(columns=[\"Head_Index\", metric_name])\n",
    "\n",
    "        # Sort heads numerically (critical)\n",
    "        heads = sorted(\n",
    "            head_stats[layer_id][projection].keys(),\n",
    "            key=lambda x: int(x.split(\"_\")[1])\n",
    "        )\n",
    "\n",
    "        for head in heads:\n",
    "            if metric_name in head_stats[layer_id][projection][head]:\n",
    "                value = head_stats[layer_id][projection][head][metric_name]\n",
    "                head_idx = int(head.split(\"_\")[1])\n",
    "                table.add_data(head_idx, value)\n",
    "\n",
    "        wandb.log({\n",
    "            f\"Layer {layer_id} {projection} Head Line Plot ({metric_name})\":\n",
    "                wandb.plot.line(\n",
    "                    table,\n",
    "                    \"Head_Index\",\n",
    "                    metric_name,\n",
    "                    title=f\"Layer {layer_id} {projection} Heads ({metric_name})\"\n",
    "                )\n",
    "        })\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # RENDER\n",
    "    # --------------------------------------------------\n",
    "    def render(self, weight_metrics=None,\n",
    "               head_layers=None):\n",
    "\n",
    "        if self.weight_stats and weight_metrics:\n",
    "            for m in weight_metrics:\n",
    "                self.plot_weight_metric_layerwise(m)\n",
    "\n",
    "            if head_layers:\n",
    "                for m in weight_metrics:\n",
    "                    for layer_id in head_layers:\n",
    "                        # self.plot_weight_metric_headwise(m, layer_id)\n",
    "                        self.plot_projection_metric_headwise_line(m, layer_id, projection=\"Q\")\n",
    "                        self.plot_projection_metric_headwise_line(m, layer_id, projection=\"K\")\n",
    "                        self.plot_projection_metric_headwise_line(m, layer_id, projection=\"V\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_model_distributions(\n",
    "    params,\n",
    "    num_heads,\n",
    "    hidden_size,\n",
    "    stats=(\"kurtosis\", \"std\"),\n",
    "    log_scale=False,\n",
    "    head_layers=None,          # NEW: which layers for head plots\n",
    "    sample_size=100_000\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes:\n",
    "        1) Weight distribution across transformer blocks\n",
    "        2) Weight distribution across attention heads\n",
    "        3) Activation statistics (optional)\n",
    "\n",
    "    Args:\n",
    "        params: Flax model params\n",
    "        num_heads: number of attention heads\n",
    "        hidden_size: model hidden dimension\n",
    "        head_layers: list of layer indices for head-level plots\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1️⃣ Weight Statistics\n",
    "    # --------------------------------------------------\n",
    "    weight_engine = WeightStatisticsEngine(\n",
    "        params=params,\n",
    "        num_heads=num_heads,\n",
    "        hidden_size=hidden_size,\n",
    "        sample_size=sample_size\n",
    "    )\n",
    "\n",
    "    weight_stats = weight_engine.compute(stats)\n",
    "    # --------------------------------------------------\n",
    "    # 3️⃣ Visualization\n",
    "    # --------------------------------------------------\n",
    "    viz = LLMDistributionVisualizer(\n",
    "        weight_stats=weight_stats,\n",
    "        log_scale=log_scale,\n",
    "        use_wandb=True\n",
    "    )\n",
    "\n",
    "    viz.render(\n",
    "        weight_metrics=stats,\n",
    "        head_layers=head_layers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_base = \"/kaggle/input/notebooks/pankajkumar2002/gpt-flax-openweeb/gpt-jax/out/checkpoints/train_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find host bounds for accelerator type: WARNING: could not determine TPU accelerator type, please set env var `TPU_ACCELERATOR_TYPE` manually, otherwise libtpu.so may not properly initialize.\n",
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1772309042.623209  154733 common_lib.cc:530] INVALID_ARGUMENT: Error: unexpected worker hostname 'WARNING: could not determine TPU worker hostnames or IP addresses' from env var TPU_WORKER_HOSTNAMES. Expecting a valid hostname or IP address without port number, or hostname:port:address triple. (Full TPU workers' addr string: WARNING: could not determine TPU worker hostnames or IP addresses, please set env var `TPU_WORKER_HOSTNAMES` manually, otherwise libtpu.so may not properly initialize.)\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/libtpu_init_utils.cc:310\n",
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded step: 101000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/batman/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimpankaj\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/batman/git/gpt-jax/wandb/run-20260301_013507-v7xtun1n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/impankaj/llm-distribution/runs/v7xtun1n' target=\"_blank\">absurd-plant-17</a></strong> to <a href='https://wandb.ai/impankaj/llm-distribution' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/impankaj/llm-distribution' target=\"_blank\">https://wandb.ai/impankaj/llm-distribution</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/impankaj/llm-distribution/runs/v7xtun1n' target=\"_blank\">https://wandb.ai/impankaj/llm-distribution/runs/v7xtun1n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for dir_ in  os.listdir(checkpoint_base):\n",
    "relative_path = \"/home/batman/git/gpt-jax/out/checkpoints/checkpoint_101000\"\n",
    "train_state = load_checkpoint(config, relative_path)\n",
    "params = train_state.params\n",
    "visualize_model_distributions(\n",
    "params,\n",
    "    num_heads=num_heads,\n",
    "    hidden_size=hidden_size,\n",
    "    stats=[\"kurtosis\", \"std\", \"spectral_norm\"],\n",
    "    log_scale=True,\n",
    "    head_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 299339721,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py313 (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
